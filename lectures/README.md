## Additional Lecture Notes


### Session 1: Introduction to Data Science

* Overview of Data Science ([slides](DAT13_lec01.pdf))

####Resources:
* Read [Analyzing the Analyzers](http://cdn.oreillystatic.com/oreilly/radarreport/0636920029014/Analyzing_the_Analyzers.pdf) for a useful look at the different types of data scientists.

---

### Session 2: Introduction to Python

* Intro to Python ([slides](DAT13_lec02_Intro_Python.pdf))
* Intro to Version Control ([slides](DAT13_lec02a-Version_Control.pdf))

####Resources:
* Read the first two chapters of [Pro Git](http://git-scm.com/book/en/v2) to gain a much deeper understanding of version control and basic Git commands.
* If you need more practice with Python, review the "1. Python Overview" section of [A Crash Course in Python](http://nbviewer.ipython.org/gist/rpmuller/5920182), work through some of [Codecademy's Python course](http://www.codecademy.com/en/tracks/python), or work through [Google's Python Class](https://developers.google.com/edu/python/) and its exercises.

---

### Session 5: Pandas

Here is a great Pandas resource:

* [Pandas Cheat Sheet](http://nbviewer.ipython.org/github/pybokeh/ipython_notebooks/blob/master/pandas/PandasCheatSheet.ipynb)

---

### Session 8: K-Means Clustering Examples

Here are the animations we saw in class for how K-Means clustering works:

* [Visualizing K-Means](http://tech.nitoyon.com/en/blog/2013/11/07/k-means/)
* [Naftali Harris: Visualizing K-Means Clustering](http://www.naftaliharris.com/blog/visualizing-k-means-clustering/)

---

### Session 12: Recommender Systems

####Resources:
* [The Netflix Prize](http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html)
* [Why Netflix never implemented the winning solution](https://www.techdirt.com/blog/innovation/articles/20120409/03412518422/why-netflix-never-implemented-algorithm-that-won-netflix-1-million-challenge.shtml)
* [Visualization of the Music Genome Project](http://www.music-map.com/)
* [The People Inside Your Machine](http://www.npr.org/blogs/money/2015/01/30/382657657/episode-600-the-people-inside-your-machine) (23 minutes) is a Planet Money podcast episode about how Amazon Mechanical Turks can assist with recommendation engines (and machine learning in general).

---

###Session 13 Pre-work:
**The following preparation work is strongly recommended, in order to get the most out of class on Monday 4/20**

* Read Paul Graham's [A Plan for Spam](http://www.paulgraham.com/spam.html) and be prepared to **discuss it in class on Monday**. Here are some questions to think about while you read:
    * Should a spam filter optimize for sensitivity or specificity, in Paul's opinion?
    * Before he tried the "statistical approach" to spam filtering, what was his approach?
    * How exactly does his statistical filtering system work?
    * What did Paul say were some of the benefits of the statistical approach?
    * How good was his prediction of the "spam of the future"?
* Monday's class will depend heavily upon fundamental concepts of probability. Please be sure to review these materials before class:
    * **Basics of probability:** These [introductory slides](https://docs.google.com/presentation/d/1cM2dVbJgTWMkHoVNmYlB9df6P2H8BrjaqAcZTaLe9dA/edit#slide=id.gfc3caad2_00) (from the [OpenIntro Statistics textbook](https://www.openintro.org/stat/textbook.php?stat_book=os)) are quite good and include integrated quizzes. Pay specific attention to these terms: probability, sample space, mutually exclusive, independent.
    * **Conditional Probability:** This [5-minute video on conditional probability](https://www.youtube.com/watch?v=Zxm4Xxvzohk), or these [slides on conditional probability](https://docs.google.com/presentation/d/1psUIyig6OxHQngGEHr3TMkCvhdLInnKnclQoNUr4G4U/edit#slide=id.gfc69f484_00) will introduce the concept of conditional probability.
    * scikit-learn documentation: [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), [Naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html)
* **Remember that the Midterm Homework 4 is due on Monday 4/20 by 6:00PM!**
* Also, you should be working on your project! **Your [first draft](https://github.com/ga-students/DAT_SF_13/blob/master/project/dat_project.md#april-26-first-draft-due) is due on April 26!**