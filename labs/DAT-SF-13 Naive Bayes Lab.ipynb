{
 "metadata": {
  "name": "",
  "signature": "sha256:1d886c36a2229f97ce4a4d182dc38720dfd484846df552e0fe99ed8d97ca9ff8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Naive Bayes Lab\n",
      "===============\n",
      "Ankit Jain"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "CLASS: Naive Bayes SMS spam classifier using sklearn\n",
      "\n",
      "Data source: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Importing Packages \n",
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## READING IN THE DATA\n",
      "df = pd.read_csv(\"sms.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine the data\n",
      "df.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.label.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.msg.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert the label into a binary variable\n",
      "df['label'] = df.label.map({'ham': 0 , 'spam':1})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split into training and testing sets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(df.msg, df.label, random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to convert the text into feature vectors which can be used for machine learning purposes.\n",
      "We will use the scikit function of CountVectorizer to 'convert text into a matrix of token counts'\n",
      "\n",
      " http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# start with a simple example\n",
      "train_simple = ['call you tonight',\n",
      "                'Call me a cab',\n",
      "                'please call me... PLEASE!']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# learn the 'vocabulary' of the training data\n",
      "vect = CountVectorizer(decode_error = 'ignore')\n",
      "vect.fit(train_simple)\n",
      "vect.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# transform training data into a 'document-term matrix'\n",
      "train_simple_dtm = vect.transform(train_simple)\n",
      "train_simple_dtm.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# examine the vocabulary and document-term matrix together\n",
      "pd.DataFrame(train_simple_dtm.toarray(), columns=vect.get_feature_names())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# transform testing data into a document-term matrix (using existing vocabulary)\n",
      "test_simple = [\"please don't call me\"]\n",
      "test_simple_dtm = vect.transform(test_simple)\n",
      "test_simple_dtm.toarray()\n",
      "pd.DataFrame(test_simple_dtm.toarray(), columns=vect.get_feature_names())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## REPEAT PATTERN WITH SMS DATA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# instantiate the vectorizer ( use variable name as vect)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# learn vocabulary and create document-term matrix in a single step ( use fit_transform) : Use Variable name as train_dtm\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# transform testing data into a document-term matrix: Use Variable name as test_dtm\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the length  and names of the feature names\n",
      "train_features = vect.get_feature_names()\n",
      "len(train_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_features[:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_features[-50:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert train_dtm to a regular array\n",
      "train_arr = train_dtm.toarray()\n",
      "train_arr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Revisit Numpy\n",
      "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
      "print arr[0, 0]\n",
      "print arr[1, 3]\n",
      "print arr[0, :]\n",
      "print arr[:, 0]\n",
      "print np.sum(arr)\n",
      "print np.sum(arr,axis = 0)\n",
      "print np.sum(arr,axis = 1)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "8\n",
        "[1 2 3 4]\n",
        "[1 5]\n",
        "36\n",
        "[ 6  8 10 12]\n",
        "[10 26]\n"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# exercise: calculate the number of tokens in the 0th message in train_arr\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# exercise: count how many times the 0th token appears across ALL messages in train_arr\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# exercise: count how many times EACH token appears across ALL messages in train_arr\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# exercise: create a DataFrame of tokens with their counts.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's build the model with Naive Bayes Now\n",
      "\n",
      "http://scikit-learn.org/stable/modules/naive_bayes.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# train a Naive Bayes model using train_dtm\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "nb = MultinomialNB()\n",
      "nb.fit(train_dtm, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make predictions on test data using test_dtm\n",
      "preds = nb.predict(test_dtm)\n",
      "preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compare predictions to true labels\n",
      "from sklearn import metrics\n",
      "print metrics.accuracy_score(y_test, preds)\n",
      "print metrics.confusion_matrix(y_test, preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict (poorly calibrated) probabilities and calculate AUC\n",
      "probs = nb.predict_proba(test_dtm)[:, 1]\n",
      "probs\n",
      "print metrics.roc_auc_score(y_test, probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# exercise: show the message text for the false positives\n",
      "X_test[y_test < preds]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# exercise: show the message text for the false negatives\n",
      "X_test[y_test > preds]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## COMPARE NAIVE BAYES AND LOGISTIC REGRESSION\n",
      "## USING ALL DATA AND CROSS-VALIDATION\n",
      "\n",
      "# create a document-term matrix using all data\n",
      "all_dtm = vect.fit_transform(df.msg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# instantiate logistic regression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "logreg = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compare AUC using cross-validation\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "print \"Naives Bayes Cross Val Score is {}\".format(cross_val_score(nb, all_dtm, df.label, cv=10, scoring='roc_auc').mean())\n",
      "print \"Log Reg Cross Val Score is {}\".format(cross_val_score(logreg, all_dtm, df.label, cv=10, scoring='roc_auc').mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Naives Bayes Cross Val Score is 0.983474271119\n",
        "Log Reg Cross Val Score is 0.987968364798"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## EXERCISE: CALCULATE THE 'SPAMMINESS' OF EACH TOKEN\n",
      "\n",
      "# create separate DataFrames for ham and spam ( df_ham and df_spam)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# learn the vocabulary of ALL messages and save it\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create document-term matrix of ham, then convert to a regular array\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# create document-term matrix of spam, then convert to a regular array\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# count how many times EACH token appears across ALL messages in ham_arr\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# count how many times EACH token appears across ALL messages in spam_arr\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a DataFrame of tokens with their separate ham and spam counts\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add one to ham counts and spam counts so that ratio calculations (below) make more sensse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate ratio of spam-to-ham for each token\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}